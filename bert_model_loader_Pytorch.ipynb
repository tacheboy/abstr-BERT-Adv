{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82ac62e8df664fe8988db47f74f7adc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f7fa705742e4e8995047c4acf1a85ce",
              "IPY_MODEL_b8da82765d4f4698b34f062f2e9ca09f",
              "IPY_MODEL_441ed55903e945e1858852a1487d09f3"
            ],
            "layout": "IPY_MODEL_ddb09da13bff4a92821fc9d1cb7ca8d0"
          }
        },
        "2f7fa705742e4e8995047c4acf1a85ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e1b3b51e894a4280b864cac210952a",
            "placeholder": "​",
            "style": "IPY_MODEL_605f3ce693a245ab959be94401eeae7e",
            "value": "model.safetensors: 100%"
          }
        },
        "b8da82765d4f4698b34f062f2e9ca09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8008911305b34b538c6d51b3a27d65d0",
            "max": 69569488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c5f29c043834544a615253580ad71b8",
            "value": 69569488
          }
        },
        "441ed55903e945e1858852a1487d09f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d2da89d47d45dea1c117e90d609a5f",
            "placeholder": "​",
            "style": "IPY_MODEL_2a4a4789f3884783ac8a742c8c78bc57",
            "value": " 69.6M/69.6M [00:00&lt;00:00, 128MB/s]"
          }
        },
        "ddb09da13bff4a92821fc9d1cb7ca8d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e1b3b51e894a4280b864cac210952a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605f3ce693a245ab959be94401eeae7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8008911305b34b538c6d51b3a27d65d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5f29c043834544a615253580ad71b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32d2da89d47d45dea1c117e90d609a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4a4789f3884783ac8a742c8c78bc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXUYA-cBZm4Y"
      },
      "source": [
        "!pip install -q transformers  rouge-score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqq1Pf-fZAWL",
        "outputId": "ef431cff-68f9-4636-ce3e-1647ad6f775c"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "sentence_model = \"sentence-transformers/paraphrase-MiniLM-L3-v2\"\n",
        "# use \"sentence-transformers/all-mpnet-base-v2\" to get better accuracy\n",
        "# refer to: https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#sentence-embedding-models for more information\n",
        "tokenizer = AutoTokenizer.from_pretrained(sentence_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuaWsg8I1UH6",
        "outputId": "02ac2ccf-ed5d-4116-87f6-47fb376b8bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install spacy\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "tZ8uexEz1jI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "aee7d4a0-9309-4864-fa10-60635854137d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvTweWCpAYB2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skg7YcvmLrc5",
        "outputId": "c7617e81-d0bc-496f-df59-372a1476b493"
      },
      "source": [
        "# Hyper-Parameters that seems to work best. You can change them if you want\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "# load dataframes containining preprocessed samples from CNN/Dailymail Dataset\n",
        "train_df = pd.read_json(\"drive/MyDrive/data/merged.json\")\n",
        "test_df = pd.read_json(\"drive/MyDrive/data/test_bdf.json\")\n",
        "print(f\"Train: {train_df.shape}, test shape: {test_df.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (530199, 3), test shape: (36195, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfvcGP11Goey"
      },
      "source": [
        "## Create a Data Loader Class\n",
        "\n",
        "- Create a dataloader class that yields sentences and documentss and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTmrs5blGurr"
      },
      "source": [
        "class cnndmData(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence = str(self.data.iloc[index].sents)\n",
        "        sentence = \" \".join(sentence.split())\n",
        "\n",
        "        document = str(self.data.iloc[index].docs)\n",
        "        document = \" \".join(document.split())\n",
        "\n",
        "        inputs = self.tokenizer.batch_encode_plus(\n",
        "            [sentence, document],\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'sent_ids': torch.tensor(ids[0], dtype=torch.long),\n",
        "            'doc_ids': torch.tensor(ids[1], dtype=torch.long),\n",
        "            'sent_mask': torch.tensor(mask[0], dtype=torch.long),\n",
        "            'doc_mask': torch.tensor(mask[1], dtype=torch.long),\n",
        "            'targets': torch.tensor([self.data.iloc[index].y], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "training_set = cnndmData(train_df, tokenizer, MAX_LEN)\n",
        "testing_set = cnndmData(test_df, tokenizer, MAX_LEN)\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE, 'shuffle': True, 'num_workers': 0}\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE, 'shuffle': True, 'num_workers': 0}\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMe7OT5YHadU"
      },
      "source": [
        "## Build Model\n",
        "\n",
        "- Build model based on sentence Bert pretrained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6KuhukuZA1x"
      },
      "source": [
        "# get mean pooling for sentence bert models\n",
        "# ref https://www.sbert.net/examples/applications/computing-embeddings/README.html#sentence-embeddings-with-transformers\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "\n",
        "# adding a drop out and a dense layer to vanilla bert to get the final output for the model.\n",
        "# Note that different sentence transformer models may have different in_feature sizes\n",
        "class SentenceBertClass(torch.nn.Module):\n",
        "    def __init__(self, model_name=sentence_model, in_features=384):\n",
        "        super(SentenceBertClass, self).__init__() # inherit init of SentenceBert\n",
        "        self.l1 = AutoModel.from_pretrained(model_name)\n",
        "        self.pre_classifier = torch.nn.Linear(in_features*3, 768)\n",
        "        # self.pre_classifier = torch.nn.Linear(in_features * 3, 512)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 1)\n",
        "        self.classifierSigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, sent_ids=None, doc_ids=None, sent_mask=None, doc_mask=None, inputs_embeds=None):\n",
        "\n",
        "        # sent_output = self.l1(input_ids=sent_ids, attention_mask=sent_mask)\n",
        "        # sentence_embeddings = mean_pooling(sent_output, sent_mask)\n",
        "\n",
        "        if inputs_embeds is None: # check if inputs_embeds is provided\n",
        "            sent_output = self.l1(input_ids=sent_ids, attention_mask=sent_mask)\n",
        "        else:\n",
        "            sent_output = self.l1(inputs_embeds=inputs_embeds, attention_mask=sent_mask) # use inputs_embeds if provided\n",
        "        sentence_embeddings = mean_pooling(sent_output, sent_mask)\n",
        "\n",
        "        doc_output = self.l1(input_ids=doc_ids, attention_mask=doc_mask)\n",
        "        doc_embeddings = mean_pooling(doc_output, doc_mask)\n",
        "\n",
        "        # elementwise product of sentence embs and doc embs\n",
        "        combined_features = sentence_embeddings * doc_embeddings\n",
        "\n",
        "        # Concatenate input features and their elementwise product\n",
        "        concat_features = torch.cat((sentence_embeddings, doc_embeddings, combined_features), dim=1)\n",
        "\n",
        "        pooler = self.pre_classifier(concat_features)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        output = self.classifierSigmoid(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "82ac62e8df664fe8988db47f74f7adc8",
            "2f7fa705742e4e8995047c4acf1a85ce",
            "b8da82765d4f4698b34f062f2e9ca09f",
            "441ed55903e945e1858852a1487d09f3",
            "ddb09da13bff4a92821fc9d1cb7ca8d0",
            "13e1b3b51e894a4280b864cac210952a",
            "605f3ce693a245ab959be94401eeae7e",
            "8008911305b34b538c6d51b3a27d65d0",
            "8c5f29c043834544a615253580ad71b8",
            "32d2da89d47d45dea1c117e90d609a5f",
            "2a4a4789f3884783ac8a742c8c78bc57"
          ]
        },
        "id": "Kz01GdtMeTHg",
        "outputId": "1e993211-b55e-46bd-a6e3-15a8686d9e24"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "model = SentenceBertClass(model_name=sentence_model)\n",
        "model.to(device);\n",
        "\n",
        "loss_function = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/69.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82ac62e8df664fe8988db47f74f7adc8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, input_dim=768):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_dim, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 256)\n",
        "        self.fc3 = torch.nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Initialize Discriminator\n",
        "discriminator = Discriminator(input_dim=768)  # Adjust based on your feature size\n",
        "discriminator.to(device)\n",
        "\n",
        "# Loss and Optimizers for adversarial learning\n",
        "adv_loss_fn = torch.nn.BCELoss()  # For Discriminator\n",
        "adv_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "C2wIW5JUvW1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_examples(embeddings, ep=1e-5):\n",
        "    perturbation = torch.randn_like(embeddings) * ep\n",
        "    adversarial_embeddings = embeddings + perturbation\n",
        "    return adversarial_embeddings"
      ],
      "metadata": {
        "id": "5R-Esv0-vkpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9VNz4HGXGVI"
      },
      "source": [
        "# VANILLA\n",
        "# NO Adversarial Training\n",
        "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
        "print_n_steps = 1000\n",
        "EPOCHS = 3\n",
        "acc_step_holder, loss_step_holder = [], []\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for _,data in tqdm(enumerate(training_loader, 0)):  # remove tqdm if u dont want the progress bar... i found it pretty in someone else's code so\n",
        "        sent_ids = data['sent_ids'].to(device, dtype = torch.long)\n",
        "        doc_ids = data['doc_ids'].to(device, dtype = torch.long)\n",
        "        sent_mask = data['sent_mask'].to(device, dtype = torch.long)\n",
        "        doc_mask = data['doc_mask'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(sent_ids, doc_ids, sent_mask, doc_mask)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()\n",
        "        n_correct += torch.count_nonzero(targets == (outputs > 0.5)).item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples+=targets.size(0)\n",
        "\n",
        "        if _%print_n_steps==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct*100)/nb_tr_examples\n",
        "            print(str(_* train_params[\"batch_size\"]) + \"/\" + str(len(train_df)) + \" - Steps. Acc ->\", accu_step, \"Loss ->\", loss_step)\n",
        "            acc_step_holder.append(accu_step), loss_step_holder.append(loss_step)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # # When using GPU\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN LIKE\n",
        "print_n_steps = 1000\n",
        "EPOCHS = 3\n",
        "acc_step_holder, loss_step_holder = [], []\n",
        "\n",
        "def train(epoch):\n",
        "    tr_loss = 0\n",
        "    adv_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    for _, data in tqdm(enumerate(training_loader, 0)):\n",
        "        sent_ids = data['sent_ids'].to(device, dtype=torch.long)\n",
        "        doc_ids = data['doc_ids'].to(device, dtype=torch.long)\n",
        "        sent_mask = data['sent_mask'].to(device, dtype=torch.long)\n",
        "        doc_mask = data['doc_mask'].to(device, dtype=torch.long)\n",
        "        targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "        # Generator Forward Pass\n",
        "        outputs = model(sent_ids, doc_ids, sent_mask, doc_mask)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        # Generate Adversarial Examples\n",
        "        sent_output = model.l1(input_ids=sent_ids, attention_mask=sent_mask)\n",
        "        sent_embeddings = mean_pooling(sent_output, sent_mask)  # Get embeddings from the generator\n",
        "\n",
        "        sent_embeddings = sent_embeddings.view(-1, 768)\n",
        "\n",
        "        adv_embeddings = generate_adversarial_examples(sent_embeddings)\n",
        "\n",
        "        # Discriminator Forward Pass\n",
        "        real_labels = torch.ones(sent_embeddings.size(0), 1).to(device)\n",
        "        fake_labels = torch.zeros(adv_embeddings.size(0), 1).to(device)\n",
        "\n",
        "        real_outputs = discriminator(sent_embeddings.detach())  # Detach from the Generator graph\n",
        "        fake_outputs = discriminator(adv_embeddings.detach())  # Detach so generator doesn’t get updated here\n",
        "\n",
        "        real_loss = adv_loss_fn(real_outputs, real_labels)\n",
        "        fake_loss = adv_loss_fn(fake_outputs, fake_labels)\n",
        "        discriminator_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        adv_loss += discriminator_loss.item()\n",
        "\n",
        "        # Backprop Discriminator\n",
        "        adv_optimizer.zero_grad()\n",
        "        discriminator_loss.backward()\n",
        "        adv_optimizer.step()\n",
        "\n",
        "        # Fool the Discriminator\n",
        "        fooling_loss = adv_loss_fn(discriminator(adv_embeddings), real_labels)  # Generator tries to fool Discriminator\n",
        "\n",
        "        # Add the adversarial loss to the generator's loss\n",
        "        total_loss = loss + fooling_loss\n",
        "\n",
        "        # Backprop Generator\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        n_correct += torch.count_nonzero(targets == (outputs > 0.5)).item()\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if _ % print_n_steps == 0:\n",
        "            loss_step = tr_loss / nb_tr_steps\n",
        "            accu_step = (n_correct * 100) / nb_tr_examples\n",
        "            print(f\"{_ * train_params['batch_size']}/{len(train_df)} - Steps. Acc -> {accu_step}, Loss -> {loss_step}\")\n",
        "            acc_step_holder.append(accu_step), loss_step_holder.append(loss_step)\n",
        "\n",
        "    print(f\"The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}\")\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    epoch_accu = (n_correct * 100) / nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "    print(f\"Adversarial Loss: {adv_loss / nb_tr_steps}\")\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "sKgL46BMvp2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcvWDsNCXSlY",
        "collapsed": true
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e89U858K4-5L"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,5))\n",
        "ax1.plot(acc_step_holder, label=\"Accuracy\")\n",
        "ax2.plot(loss_step_holder, label=\"Loss\")\n",
        "ax1.title.set_text(\"Accuracy\")\n",
        "ax2.title.set_text(\"Loss\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbVctlGRIlLg"
      },
      "source": [
        "## Validation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VnPNTT3Ikic"
      },
      "source": [
        "# validation was heavily inspired by a blog and ChatGPT\n",
        "def validate_model(model, testing_loader):\n",
        "    model.eval()\n",
        "\n",
        "    n_correct = 0; n_wrong = 0; total = 0;  tr_loss = 0; nb_tr_steps = 0 ; nb_tr_examples = 0;\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "\n",
        "            sent_ids = data['sent_ids'].to(device, dtype = torch.long)\n",
        "            doc_ids = data['doc_ids'].to(device, dtype = torch.long)\n",
        "            sent_mask = data['sent_mask'].to(device, dtype = torch.long)\n",
        "            doc_mask = data['doc_mask'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            outputs = model(sent_ids, doc_ids, sent_mask, doc_mask)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()\n",
        "\n",
        "            n_correct += torch.count_nonzero(targets == (outputs > 0.5)).item()\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples+=targets.size(0)\n",
        "\n",
        "            if _%print_n_steps==0:\n",
        "                loss_step = tr_loss/nb_tr_steps\n",
        "                accu_step = (n_correct*100)/nb_tr_examples\n",
        "                print(str(_* test_params[\"batch_size\"]) + \"/\" + str(len(train_df)) + \" - Steps. Acc ->\", accu_step, \"Loss ->\", loss_step)\n",
        "\n",
        "\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return epoch_accu\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpxAOk89JT6Y"
      },
      "source": [
        "acc = validate_model(model, testing_loader)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk9qmEtmNUWA"
      },
      "source": [
        "## Save Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOcf6XM9YhI5"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"drive/MyDrive/data/models\", exist_ok=True)\n",
        "torch.save(model.state_dict(), \"drive/MyDrive/data/models/bal_model.pth\")\n",
        "!gsutil cp -r models $sum_dir"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}